{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4f9661-785e-441b-9467-02e5561e1fdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "# !{sys.executable} -m pip install flash-attn==2.8.0.post2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d258a8ae-59cd-4b97-a0d1-3c16b0c3925e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "print(\"CUDA available?\", torch.cuda.is_available())\n",
    "print(\"CUDA device count:\", torch.cuda.device_count())\n",
    "print(\"CUDA device name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"N/A\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206f517d-2aee-4dd7-be40-76b796150a84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting cell 1\n",
      "Using device: cuda\n",
      "CUDA device name: NVIDIA A40\n",
      "Loading tokenizer and model 'hugging-quants/Meta-Llama-3.1-8B-Instruct-GPTQ-INT4' for the first time...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/miniconda3/envs/myenv/lib/python3.11/site-packages/auto_gptq/nn_modules/triton_utils/kernels.py:410: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "/home/jovyan/miniconda3/envs/myenv/lib/python3.11/site-packages/auto_gptq/nn_modules/triton_utils/kernels.py:418: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "/home/jovyan/miniconda3/envs/myenv/lib/python3.11/site-packages/auto_gptq/nn_modules/triton_utils/kernels.py:461: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd(cast_inputs=torch.float16)\n",
      "CUDA extension not installed.\n",
      "CUDA extension not installed.\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup and Global Model Loading\n",
    "print(\"Starting cell 1\")\n",
    "# Standard imports for model loading and type hinting\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch # Often used for model operations (e.g., moving to GPU, data types)\n",
    "from typing import Any, Dict\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(f\"CUDA device name: {torch.cuda.get_device_name(0)}\") # Prints GPU name (e.g., NVIDIA A100)\n",
    "\n",
    "\n",
    "# Define the path to your model\n",
    "# MODEL_NAME = \"models/Meta-Llama-3-8B-Instruct\"\n",
    "MODEL_NAME = \"hugging-quants/Meta-Llama-3.1-8B-Instruct-GPTQ-INT4\"\n",
    "\n",
    "# --- Global Model Loading Logic ---\n",
    "# This check ensures the model is loaded only once per kernel session.\n",
    "# If you restart your Jupyter kernel, this cell will execute and load the model again.\n",
    "if 'global_tokenizer' not in globals():\n",
    "    print(f\"Loading tokenizer and model '{MODEL_NAME}' for the first time...\")\n",
    "    \n",
    "    # Load tokenizer\n",
    "    global_tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=False)\n",
    "    \n",
    "    # Load model. \n",
    "    # Also, move to GPU if available.\n",
    "    global_model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"CUDA available\")\n",
    "        global_model.to('cuda')\n",
    "\n",
    "    print(\"Model loaded.\")\n",
    "else:\n",
    "    print(\"Model already loaded. Reusing existing instances.\")\n",
    "\n",
    "# Optional: Print basic info to confirm\n",
    "print(f\"Tokenizer: {type(global_tokenizer)}\")\n",
    "print(f\"Model: {type(global_model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2e3f1e-340b-4fc3-9065-0e860a83a070",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json, pprint, os, sys\n",
    "from IPython.display import Image, display\n",
    "from datetime import datetime\n",
    "from agents.orchestrator import orchestrator\n",
    "from agents.information_gatherer import information_gatherer\n",
    "from agents.reflector import reflector\n",
    "from agents.final_formatter import final_formatter\n",
    "from graph import build_graph\n",
    "from agents.BaseAgent import AgentState\n",
    "print(\"Starting this cell!\")\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2, width=100)\n",
    "\n",
    "initial_state = {\n",
    "    \"input\": \"\"\"I need to generate a storyboard (images and text needed, remmeber to find and extract videos) \n",
    "    about the Singapore SG60 National Day Parade, and try to encourage some nationalism and patriotism\"\"\",   # your top-level query\n",
    "    \"plan\": None,\n",
    "    \"knowledge\": [],\n",
    "    \"draft_story\": None,\n",
    "    \"reflection\": None,\n",
    "    \"final_output\": None,\n",
    "    \"status\": \"needs_info\", \n",
    "    \"candidates\": None,\n",
    "    \"needs\": []\n",
    "}\n",
    "\n",
    "# user_query =  \"\"\"I need to generate a storyboard (images and text needed, remmeber to find and extract videos) \n",
    "#     about the Singapore SG60 National Day Parade, and try to encourage some nationalism and patriotism\"\"\"\n",
    "# initial_state = AgentState(user_query=user_query)\n",
    "# print(initial_state)\n",
    "\n",
    "#Build Graph\n",
    "orch_node = lambda initial_state: orchestrator(global_model, global_tokenizer, initial_state)\n",
    "final_node = lambda initial_state: final_formatter(global_model, global_tokenizer, initial_state)\n",
    "# print(f\"\\n\\n Orch node is of type {type(orch_node)}\")\n",
    "app = build_graph(\n",
    "    orchestrator_node=orch_node,\n",
    "    information_gatherer_node=information_gatherer,\n",
    "    final_formatter_node=final_node,\n",
    ")\n",
    "\n",
    "# show a diagram if available\n",
    "try:\n",
    "    png_bytes = app.get_graph().draw_mermaid_png()\n",
    "    display(Image(data=png_bytes))\n",
    "except Exception as e:\n",
    "    print(\"[note] couldn't render mermaid png:\", e)\n",
    "\n",
    "# pp.pprint(initial_state)\n",
    "final_state = app.invoke(initial_state)\n",
    "print(\"Final state:\", final_state)\n",
    "\n",
    "\n",
    "# # --- 3) utility: pretty-print state diffs each hop ---\n",
    "# def run_once(app, initial_state: dict):\n",
    "#     print(\"=== RUN @\", datetime.now().strftime(\"%H:%M:%S\"), \"===\")\n",
    "#     print(\"initial_state:\")\n",
    "#     pp.pprint(initial_state)\n",
    "#     print(\"\\n--- streaming updates ---\")\n",
    "#     try:\n",
    "#         for update in app.stream(initial_state, stream_mode=\"updates\"):\n",
    "#             # each `update` is a dict of state writes at that step\n",
    "#             print(\"Update!\\n\")\n",
    "#             print(json.dumps(update, indent=2))\n",
    "#     except TypeError:\n",
    "#         # some langgraph versions expect stream_mode=[\"updates\",\"values\"]\n",
    "#         for update in app.stream(initial_state, stream_mode=[\"updates\",\"values\"]):\n",
    "#             print(json.dumps(update, indent=2))\n",
    "\n",
    "#     print(\"\\n--- final values ---\")\n",
    "#     final = app.invoke(initial_state)\n",
    "#     pp.pprint(final)\n",
    "#     return final\n",
    "\n",
    "\n",
    "# # --- 4) example: minimal state to kick off the graph ---\n",
    "\n",
    "\n",
    "# final_state = run_once(app, initial_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d3dbff-911b-4169-ad50-4df1f8fb020b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# What AgentState are YOU using here?\n",
    "from agents.BaseAgent import AgentState as NB_AgentState  # or just use AgentState if in the same cell\n",
    "print(\"NB AgentState:\", NB_AgentState, NB_AgentState.__module__)\n",
    "\n",
    "# What AgentState is PlanningAgent using?\n",
    "import agents.PlanningAgent as PA\n",
    "print(\"PA.AgentState:\", PA.AgentState, PA.AgentState.__module__)\n",
    "\n",
    "# Are they literally the same class?\n",
    "import agents.BaseAgent as SS  # <-- replace with wherever your canonical AgentState is\n",
    "print(\"PlanningAgent uses same AgentState as SS?\", PA.AgentState is SS.AgentState)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e624bc-b50c-41ac-8d6b-2699982fcb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To display the eventual storyboard as an output\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def display_storyboard(storyboard):\n",
    "    \"\"\"\n",
    "    Given a storyboard list of dicts with keys 'image_path' and 'caption',\n",
    "    displays each image with its caption underneath in a Jupyter notebook.\n",
    "    \"\"\"\n",
    "    for scene in storyboard:\n",
    "        display(HTML(f\"\"\"\n",
    "        <figure style=\"max-width:600px; margin: 20px 0;\">\n",
    "            <img src=\"{scene['image_path']}\" \n",
    "                 style=\"width:100%; height:auto; border:1px solid #ccc; border-radius:4px;\" />\n",
    "            <figcaption style=\"text-align:center; font-style:italic; color:#555; margin-top:5px;\">\n",
    "                {scene['caption']}\n",
    "            </figcaption>\n",
    "        </figure>\n",
    "        \"\"\"))\n",
    "display_storyboard(final_state)\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a242d25-0d6b-4baa-87d3-27cd2bfaa430",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, json\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "def _to_served_src(p: str) -> str:\n",
    "    # debug: print before and after\n",
    "    # print(f'Before: {p}')\n",
    "    # strip stray spaces before extension\n",
    "    p = p.replace(\".jpg\", \" .jpg\").replace(\".png\", \" .png\")\n",
    "    # remove any leading /home/jovyan/ if it exists\n",
    "    p = p.replace(\"/home/jovyan/\", \"\")\n",
    "    # print(f'After: {p}')\n",
    "    # return relative path (browser will look under Jupyter's served root)\n",
    "    return p\n",
    "\n",
    "\n",
    "def display_storyboard(final_state):\n",
    "    # 1) prefer final_output.storyboard; fallback to knowledge\n",
    "    items = []\n",
    "    fo = final_state.get(\"final_output\")\n",
    "    if isinstance(fo, str) and fo.strip():\n",
    "        try:\n",
    "            obj = json.loads(fo)\n",
    "            for s in obj.get(\"storyboard\", []) or []:\n",
    "                items.append({\n",
    "                    \"image_path\": s.get(\"image_path\", \"\"),\n",
    "                    \"caption\": s.get(\"frame_caption\") or s.get(\"caption\") or \"\"\n",
    "                })\n",
    "        except Exception:\n",
    "            pass\n",
    "    if not items:\n",
    "        for k in final_state.get(\"knowledge\", []) or []:\n",
    "            items.append({\"image_path\": k.get(\"image_path\",\"\"), \"caption\": k.get(\"caption\",\"\")})\n",
    "\n",
    "    # 2) render\n",
    "    parts = []\n",
    "    for i, it in enumerate(items, 1):\n",
    "        raw_path = it[\"image_path\"]\n",
    "        served = _to_served_src(raw_path)\n",
    "        # optional: warn if file missing\n",
    "        fs_path = served.removeprefix(\"/files\")\n",
    "        if not os.path.exists(fs_path):\n",
    "            parts.append(f\"<p style='color:#c00'>[Missing file] {fs_path}</p>\")\n",
    "        parts.append(f\"\"\"\n",
    "        <figure style=\"max-width:700px;margin:16px 0\">\n",
    "          <img src=\"{served}\" style=\"width:100%;height:auto;border:1px solid #ddd;border-radius:6px\" />\n",
    "          <figcaption style=\"text-align:center;color:#555;margin-top:6px\">\n",
    "            <strong>Scene {i}.</strong> {it['caption']}\n",
    "          </figcaption>\n",
    "        </figure>\n",
    "        \"\"\")\n",
    "    display(HTML(\"\\n\".join(parts) if parts else \"<em>No storyboard items.</em>\"))\n",
    "display_storyboard(final_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
